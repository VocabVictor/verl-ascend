

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>配置说明 &mdash; VERL 中文文档</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
    <link rel="canonical" href="https://vocabvictor.github.io/verl-ascend/zh/examples/config.html" />
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/translations.js?v=beaddf03"></script>
      <script src="../_static/js/runllm-widget.js?v=53011e60"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="近端策略优化 (PPO)" href="../algo/ppo.html" />
    <link rel="prev" title="更多资源" href="../start/more_resources.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../index.html" class="icon icon-home">
            verl - 中文文档
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="搜索文档" aria-label="搜索文档" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="导航菜单">
              <p class="caption" role="heading"><span class="caption-text">快速开始</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../start/install.html">安装</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../start/install.html#id2">需求</a></li>
<li class="toctree-l2"><a class="reference internal" href="../start/install.html#id5">后端引擎的选择</a></li>
<li class="toctree-l2"><a class="reference internal" href="../start/install.html#docker">从 Docker 镜像安装</a></li>
<li class="toctree-l2"><a class="reference internal" href="../start/install.html#id6">从自定义环境安装</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../start/install.html#id7">前提条件</a></li>
<li class="toctree-l3"><a class="reference internal" href="../start/install.html#id10">安装依赖</a></li>
<li class="toctree-l3"><a class="reference internal" href="../start/install.html#verl">安装 verl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../start/install.html#id11">安装后</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../start/install.html#amd-gpu-rocm">在 AMD GPU 上安装 - ROCM 内核支持</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../start/install.html#id12">构建镜像</a></li>
<li class="toctree-l3"><a class="reference internal" href="../start/install.html#id13">启动容器</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../start/quickstart.html">快速入门：在GSM8K数据集上进行PPO训练</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../start/quickstart.html#id2">介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../start/quickstart.html#id4">数据集介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../start/quickstart.html#id5">步骤 1：准备数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="../start/quickstart.html#id10">步骤 2：下载后训练模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../start/quickstart.html#ppo">步骤 3：使用指令模型进行 PPO 训练</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../start/multinode.html">多节点训练</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../start/multinode.html#id2">手册</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../start/multinode.html#ray">设置多节点 Ray 集群</a></li>
<li class="toctree-l3"><a class="reference internal" href="../start/multinode.html#id3">提交作业到 Ray 集群</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../start/multinode.html#slurm">Slurm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../start/multinode.html#dstack">dstack</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../start/multinode.html#id12">先决条件</a></li>
<li class="toctree-l3"><a class="reference internal" href="../start/multinode.html#id19">运行 Ray 集群任务</a></li>
<li class="toctree-l3"><a class="reference internal" href="../start/multinode.html#id40">提交 Ray 作业</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../start/multinode.html#id50">如何进行调试？</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../start/multinode.html#ray-vscode">Ray 分布式调试器 VSCode 扩展（推荐）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../start/multinode.html#id68">遗留 Ray 调试器</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../start/multinode.html#amd">多节点训练在AMD集群上</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../start/multinode.html#slurm-script-sh">slurm_script.sh</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../start/multinode.html#id74">###以下设置应在不同的项目和集群中进行设置###</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../start/multinode.html#id111">运行多节点训练，使用上述 slurm_script.sh</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../start/ray_debug_tutorial.html">Ray 调试教程</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../start/ray_debug_tutorial.html#id1">如何调试？</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../start/ray_debug_tutorial.html#ray-vscode">Ray 分布式调试器 VSCode 扩展（推荐）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../start/ray_debug_tutorial.html#id11">遗留 Ray 调试器</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../start/more_resources.html">更多资源</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">配置</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">配置说明</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#rl-fsdpppo-trainer-yaml">用于RL FSDP后端的ppo_trainer.yaml</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">数据</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">定制数据集</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">演员/回放/参考策略</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#megatron">Megatron 优化器和优化器参数调度器</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#critic">Critic 模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reward">Reward 模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id27">自定义奖励函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id30">算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id32">训练器</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#evaluation-yaml">evaluation.yaml</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id49">数据</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id54">自定义奖励函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id79">模型</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">算法</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../algo/ppo.html">近端策略优化 (PPO)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/ppo.html#id1">关键组件</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../algo/ppo.html#id2">PPO</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/ppo.html#id3">配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/ppo.html#id4">高级扩展</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../algo/ppo.html#kl">KL 散度控制</a></li>
<li class="toctree-l3"><a class="reference internal" href="../algo/ppo.html#id5">双重剪切 PPO</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../algo/ppo.html#id6">参考示例</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../algo/grpo.html">组相对策略优化 (GRPO)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/grpo.html#id1">关键组件</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/grpo.html#id2">配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/grpo.html#id3">高级扩展</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../algo/grpo.html#drgrpo">DrGRPO</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../algo/grpo.html#id4">参考示例</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../algo/dapo.html">配方: 分离的剪辑和动态采样策略优化 (DAPO)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/dapo.html#id1">快速入门</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/dapo.html#id2">复现运行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/dapo.html#id3">配置</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../algo/dapo.html#epsilons">分离剪裁 Epsilons (-&gt; 剪裁-更高)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../algo/dapo.html#id4">动态采样（带有分组过滤）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../algo/dapo.html#id5">灵活的损失聚合模式 (-&gt; 标记级损失)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../algo/dapo.html#id6">过长奖励塑造</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../algo/dapo.html#faq">常见问题解答 (FAQ)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../algo/dapo.html#overlong-filtering">论文中的&quot;过长过滤(Overlong Filtering)&quot;在哪里？</a></li>
<li class="toctree-l3"><a class="reference internal" href="../algo/dapo.html#mainrecipe-daporecipe-dapo">在<code class="docutils literal notranslate"><span class="pre">main</span></code>分支中的<code class="docutils literal notranslate"><span class="pre">recipe/dapo</span></code>目录与<code class="docutils literal notranslate"><span class="pre">recipe/dapo</span></code>分支有什么区别？</a></li>
<li class="toctree-l3"><a class="reference internal" href="../algo/dapo.html#id7">为什么我在修改后无法产生类似的结果？</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../algo/spin.html">食谱：自我对弈微调 (SPIN)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/spin.html#compute-online-dpo-loss">关键功能 (compute_online_dpo_loss) 和相关工作</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/spin.html#dpo">我们的在线 DPO 实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/spin.html#id1">算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/spin.html#id2">重现实验 (示例设置)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/spin.html#id3">配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/spin.html#id4">关键文件</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/spin.html#id5">致谢</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../algo/sppo.html">配方：自我游戏偏好优化 (SPPO)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/sppo.html#id1">重现实验</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/sppo.html#id2">致谢</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../algo/entropy.html">配方: 熵机制</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algo/entropy.html#id2">大型语言模型推理的强化学习熵机制</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/entropy.html#id3">🎉新闻</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/entropy.html#id4">✨开始使用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/entropy.html#id5">📖介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/entropy.html#id6">📃评估</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/entropy.html#id7">🎈引用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/entropy.html#acknowledgement">🌻Acknowledgement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/entropy.html#id8">📬 联系方式</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../algo/opo.html">最优奖励基线的在线策略强化学习 (OPO)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/opo.html#id1">关键组件</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/opo.html#id2">配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/opo.html#id3">高级扩展</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../algo/baseline.html">算法基准</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/baseline.html#id2">与数学相关的数据集</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../algo/baseline.html#gsm8k">GSM8k</a></li>
<li class="toctree-l3"><a class="reference internal" href="../algo/baseline.html#dapo-17k">DAPO 数学-17k</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../algo/baseline.html#id3">与编码相关的数据集</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../algo/baseline.html#id4">注意事项</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../algo/gpg.html">GPG: 群体策略梯度</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/gpg.html#id1">关键组件</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/gpg.html#id2">配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/gpg.html#id3">高级扩展</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PPO 训练器和工作者</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../workers/ray_trainer.html">PPO Ray Trainer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../workers/ray_trainer.html#id1">数据准备</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workers/ray_trainer.html#workergroup">WorkerGroup 初始化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workers/ray_trainer.html#ppo">PPO 训练循环</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../workers/fsdp_workers.html">PyTorch FSDP 后端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../workers/fsdp_workers.html#fsdp-workers">FSDP Workers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../workers/fsdp_workers.html#actorrolloutrefworker">ActorRolloutRefWorker</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../workers/fsdp_workers.html#actor-rollout-hybridengine">Actor/Rollout HybridEngine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../workers/fsdp_workers.html#id2">参考模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../workers/fsdp_workers.html#criticworker-rewardworker">CriticWorker 和 RewardWorker</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../workers/fsdp_workers.html#hybridshard">HybridShard</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../workers/megatron_workers.html">Megatron-LM 后端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../workers/megatron_workers.html#id1">开发进展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workers/megatron_workers.html#megatron-workers">Megatron Workers 的工具</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../workers/megatron_workers.html#megatronworker">MegatronWorker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workers/megatron_workers.html#actorrolloutrefworker">ActorRolloutRefWorker</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../workers/megatron_workers.html#actor-rollout-hybridengine">Actor/Rollout HybridEngine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../workers/megatron_workers.html#id3">参考模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../workers/megatron_workers.html#criticworker-rewardworker">CriticWorker 和 RewardWorker</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../workers/megatron_workers.html#id4">训练优化的工具</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../workers/megatron_workers.html#id5">卸载</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workers/megatron_workers.html#profiler">Profiler</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../workers/megatron_workers.html#mcore">相关 MCore 文档</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../workers/sglang_worker.html">SGLang 后端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../workers/sglang_worker.html#sglang-ppo">使用 SGLang 作为单机 PPO 训练的推理后端</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../workers/sglang_worker.html#sgl-disable-tp-memory-inbalance-check">为什么要导出SGL_DISABLE_TP_MEMORY_INBALANCE_CHECK?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../workers/sglang_worker.html#gpu">为什么会存在不一致的GPU内存？</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../workers/sglang_worker.html#sglangppo">使用SGLang作为PPO训练跨多台机器的推理后端</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">性能调优指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../perf/dpsk.html">训练 DeepSeek 671b</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../perf/dpsk.html#id1">入门指南</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../perf/dpsk.html#id2">DeepSeek 671b</a></li>
<li class="toctree-l3"><a class="reference internal" href="../perf/dpsk.html#qwen3-236b">Qwen3 236b</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../perf/dpsk.html#id3">即将到来的优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../perf/dpsk.html#id4">致谢</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../perf/perf_tuning.html">性能调优指南</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../perf/perf_tuning.html#rollout">Rollout生成调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="../perf/perf_tuning.html#id2">启用去除填充（序列打包）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../perf/perf_tuning.html#id7">批量大小调优</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../perf/perf_tuning.html#id18">批大小调优提示</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../perf/perf_tuning.html#id19">动态批量大小的调优</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../perf/perf_tuning.html#id20">动态批量大小调优技巧</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../perf/perf_tuning.html#ligerkernel-sft">LigerKernel 用于 SFT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../perf/perf_tuning.html#fsdp">FSDP 训练后端中的前向预取</a></li>
<li class="toctree-l2"><a class="reference internal" href="../perf/perf_tuning.html#logits">从 logits 计算熵的内存优化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../README_vllm0.8.html">升级至 vLLM &gt;= 0.8</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../README_vllm0.8.html#id1">安装</a></li>
<li class="toctree-l2"><a class="reference internal" href="../README_vllm0.8.html#id2">特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../README_vllm0.8.html#id3">注意事项</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../perf/device_tuning.html">硬件资源需求用于强化学习</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../perf/device_tuning.html#b">405B</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../perf/nsight_profiling.html">NVIDIA Nsight Systems 在 verl 中的性能分析</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../perf/nsight_profiling.html#id1">配置</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../perf/nsight_profiling.html#id2">先决条件</a></li>
<li class="toctree-l3"><a class="reference internal" href="../perf/nsight_profiling.html#id3">全局分析控制</a></li>
<li class="toctree-l3"><a class="reference internal" href="../perf/nsight_profiling.html#id4">工作进程分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="../perf/nsight_profiling.html#id5">在哪里找到分析数据</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../perf/nsight_profiling.html#id6">使用示例</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../perf/nsight_profiling.html#id7">禁用性能分析器</a></li>
<li class="toctree-l3"><a class="reference internal" href="../perf/nsight_profiling.html#id8">启用性能分析器并为一个训练步骤设置一个数据库</a></li>
<li class="toctree-l3"><a class="reference internal" href="../perf/nsight_profiling.html#id9">启用分析器和多个数据库以进行一次训练步骤</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../perf/nsight_profiling.html#id10">分析输出</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">高级功能</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advance/checkpoint.html">使用检查点支持容错训练</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../advance/checkpoint.html#id4">检查点保存目录结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advance/checkpoint.html#fsdpmegatron-checkpointshuggingface">将FSDP和Megatron Checkpoints转换为HuggingFace格式模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advance/checkpoint.html#megatron">Megatron(梅加特龙) 合并器详细信息</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advance/checkpoint.html#huggingfacemegatron-distcheckpoint">HuggingFace转换为Megatron DistCheckpoint详细信息</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advance/checkpoint.html#id53">原始检查点工具</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../advance/rope.html">RoPE缩放覆盖</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advance/ppo_lora.html">RL(HF) 算法与 LoRA 支持</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../advance/ppo_lora.html#id1">使用指南</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advance/ppo_lora.html#id2">最佳实践和注意事项</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advance/ppo_lora.html#id7">示例脚本</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../sglang_multiturn/multiturn.html">多轮发布支持</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/multiturn.html#id2">基本配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/multiturn.html#id3">自定义工具配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/multiturn.html#id12">多轮对话标记化</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sglang_multiturn/multiturn.html#id15">特殊情况</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sglang_multiturn/multiturn.html#id42">训练与推理模板之间的差异</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/multiturn.html#gsm8k">GSM8K 多轮训练性能</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/multiturn.html#id43">交互系统</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sglang_multiturn/interaction_system.html">多轮强化学习训练的交互系统</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id2">概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id3">架构</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id29">配置</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#gsm8k">实现示例: GSM8K</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id46">训练集成</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id55">最佳实践</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id60">高级用法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id93">故障排除</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id94">相关文档</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/multiturn.html#id44">搜索工具集成</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sglang_multiturn/search_tool_example.html">搜索工具集成</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/search_tool_example.html#id2">介绍</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/search_tool_example.html#id3">快速重现</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/search_tool_example.html#id31">自定义搜索配置</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/search_tool_example.html#id32">笔记</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/multiturn.html#id45">代码讲解</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../sglang_multiturn/interaction_system.html">多轮强化学习训练的交互系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id2">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id3">架构</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id4">核心组件</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id29">配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#gsm8k">实现示例: GSM8K</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id46">训练集成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id55">最佳实践</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id60">高级用法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id93">故障排除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/interaction_system.html#id94">相关文档</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../advance/placement.html">Ray API 设计教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advance/dpo_extension.html">扩展到其他强化学习(HF)算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../advance/dpo_extension.html#id1">整体方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advance/dpo_extension.html#dpo">示例：在线DPO</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../advance/dpo_extension.html#gpu">第1步：什么是多机多GPU计算</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../advance/dpo_extension.html#id10"><strong>注意: 如何区分控制过程和分布式计算过程</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../advance/dpo_extension.html#id11">第二步: 基于不同的分布式场景，实现单进程控制多进程数据交互</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advance/dpo_extension.html#id30">第三步：主训练循环</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sandbox_fusion_example.html">沙盒融合示例</a><ul>
<li class="toctree-l2"><a class="reference internal" href="sandbox_fusion_example.html#id2">介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="sandbox_fusion_example.html#id3">第1步：准备数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="sandbox_fusion_example.html#sandbox-fusion">第2步：设置Sandbox Fusion服务</a></li>
<li class="toctree-l2"><a class="reference internal" href="sandbox_fusion_example.html#id4">第三步: 配置训练脚本</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">硬件支持</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html">AMD (ROCM 内核) 入门指南</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html#id1">设置</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html#docker-dockerfile-rocm">docker/Dockerfile.rocm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html#id2">构建镜像：</a></li>
<li class="toctree-l3"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html#id3">运行容器</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html#root">可选：在非root模式下运行并具有用户权限</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html#id4">示例</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html#ppo">PPO</a></li>
<li class="toctree-l3"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html#grpo">GRPO</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html#docker-podman-slurm">多节点训练：使用 Docker/Podman 容器的 slurm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html#slurm-script-sh">slurm_script.sh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../amd_tutorial/amd_build_dockerfile_page.html#id5">运行 slurm_script.sh</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../amd_tutorial/amd_vllm_page.html">verl 性能调优针对 AMD (ROCm 内核)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../amd_tutorial/amd_vllm_page.html#amd-gpu-vllm">为 AMD GPU 启用睡眠模式的 vLLM 补丁</a></li>
<li class="toctree-l2"><a class="reference internal" href="../amd_tutorial/amd_vllm_page.html#cuda-rocm">启用 CUDA 图并绕过与 ROCm 相关的问题</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html">verl x Ascend</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#id1">硬件支持</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#id2">安装</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#id3">基础环境准备</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#vllm-vllm-ascend">vllm &amp; vllm-ascend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#verl">安装verl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#id12">其他三方库说明</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#id13">快速开始</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#id22">支持现状</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#id23">精度对比说明</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#id25">吞吐对比说明</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#id26">计划</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ascend_tutorial/ascend_quick_start.html#id27">声明</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API 参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/data.html">数据接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/data.html#tensordict">TensorDict</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/data.html#api">核心 API</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/single_controller.html">单控制器接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/single_controller.html#api">核心 API</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/trainer.html">Trainer 接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/trainer.html#api">核心 API</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/utils.html">实用工具</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html#python">Python 功能实用工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html#id2">文件系统实用工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html#id3">跟踪实用工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html#id4">指标实用工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html#id5">检查点管理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html#id6">数据集实用工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html#torch">Torch 功能实用工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html#id7">序列长度平衡</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html#id8">乌利西斯工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html#fsdp">FSDP工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html#id9">调试工具</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">常见问题解答</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/faq.html">常见问题解答</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../faq/faq.html#ray">Ray相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../faq/faq.html#id2">如何在使用分布式Ray进行调试时添加断点？</a></li>
<li class="toctree-l3"><a class="reference internal" href="../faq/faq.html#rayletworker">&quot;无法向raylet注册worker&quot;</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../faq/faq.html#id3">分布式训练</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../faq/faq.html#id4">如何使用 Ray 在多节点后训练时运行？</a></li>
<li class="toctree-l3"><a class="reference internal" href="../faq/faq.html#slurm-verl">如何在由 Slurm 管理的集群上使用 verl？</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../faq/faq.html#id8">安装相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../faq/faq.html#notimplementederror-tensordict-in">NotImplementedError: TensorDict(张量字典) 不支持使用 <cite>in</cite> 关键字进行成员检查。</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../faq/faq.html#id13">非法内存访问</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq/faq.html#id18">检查点</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq/faq.html#triton-compile-module-from-src">Triton <code class="docutils literal notranslate"><span class="pre">compile_module_from_src</span></code> 错误</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq/faq.html#id39">如何生成 Ray 时间线以分析训练作业的性能？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq/faq.html#wandb">如何仅为wandb设置代理？</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">开发笔记</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html">沙盒融合工具集成</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#id2">动机</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#sandbox-fusion-faas">使用Sandbox Fusion + FaaS集成进行奖励计算</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#id3">目标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#id4">非目标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#id5">设计细节</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#id6">工具架构定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#id11">配置参数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#id16">速率限制设计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#id37">工具实现</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#id56">测试计划</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#id57">单元测试</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#e2e">e2e 测试</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sglang_multiturn/sandbox_fusion.html#id66">}</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="移动版导航菜单"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">verl - 中文文档</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="页面导航">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">配置说明</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/examples/config.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="config-explain-page">
<span id="id1"></span><h1>配置说明<a class="headerlink" href="#config-explain-page" title="Link to this heading"></a></h1>
<p>最后更新：2025年06月18日。</p>
<section id="rl-fsdpppo-trainer-yaml">
<h2>用于RL FSDP后端的ppo_trainer.yaml<a class="headerlink" href="#rl-fsdpppo-trainer-yaml" title="Link to this heading"></a></h2>
<section id="id2">
<h3>数据<a class="headerlink" href="#id2" title="Link to this heading"></a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">data</span><span class="p">:</span>
<span class="w">  </span><span class="nt">tokenizer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">  </span><span class="nt">train_files</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">~/data/rlhf/gsm8k/train.parquet</span>
<span class="w">  </span><span class="nt">val_files</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">~/data/rlhf/gsm8k/test.parquet</span>
<span class="w">  </span><span class="nt">prompt_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">prompt</span>
<span class="w">  </span><span class="nt">max_prompt_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">  </span><span class="nt">max_response_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">  </span><span class="nt">train_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024</span>
<span class="w">  </span><span class="nt">return_raw_input_ids</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span><span class="w">  </span><span class="c1"># 当策略和rm之间的tokenizer不同的时候，这个应该设置为true</span>
<span class="w">  </span><span class="nt">return_raw_chat</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">  </span><span class="nt">return_full_prompt</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">  </span><span class="nt">shuffle</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">  </span><span class="nt">filter_overlong_prompts</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">  </span><span class="nt">filter_overlong_prompts_workers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">truncation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">error</span>
<span class="w">  </span><span class="nt">image_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">images</span>
<span class="w">  </span><span class="nt">trust_remote_code</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">  </span><span class="nt">custom_cls</span><span class="p">:</span>
<span class="w">     </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">     </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data.train_files</span></code>: 训练集 parquet 文件。可以是一个列表或单个文件。程序会将所有文件读取到内存中，因此文件不能太大（&lt; 100GB）。路径可以是本地路径或 HDFS 路径。对于 HDFS 路径，我们提供工具将其下载到 DRAM 并将 HDFS 路径转换为本地路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.val_files</span></code>: 验证集 parquet 文件。可以是一个列表或单个文件。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.prompt_key</span></code>: 数据集中提示（prompt）所在的字段。默认值为 'prompt'。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.max_prompt_length</span></code>: 最大提示长度。所有提示将被左填充到该长度。如果长度过长，将报告错误。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.max_response_length</span></code>: 最大响应长度。在强化学习（RL）算法（例如 PPO）中，生成的响应长度最多为此值。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.train_batch_size</span></code>: 不同 RL 算法一个训练迭代中采样的批大小。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.return_raw_input_ids</span></code>: 是否返回原始的 input_ids，而不添加聊天模板。这主要用于适应奖励模型的聊天模板与策略不同的情况。需要先解码，然后应用 RM 的聊天模板。如果使用基于模型的 RM，并且策略和 RM 聊天模板不同，则需要设置此标志。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.return_raw_chat</span></code>: 是否返回原始聊天（提示），而不应用聊天模板。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.return_full_prompt</span></code>: 是否返回带有聊天模板的完整提示。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.shuffle</span></code>: 是否在数据加载器中打乱数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.filter_overlong_prompts</span></code>: 默认不进行过滤。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.filter_overlong_prompts_workers</span></code>: 对于大规模数据集，过滤过长提示可能会耗时。您可以设置 <code class="docutils literal notranslate"><span class="pre">filter_overlong_prompts_workers</span></code> 以使用多进程加速。默认值为 1。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.truncation</span></code>: 如果输入_ids 或提示长度超过 max_prompt_length，则截断。默认值为 'error'，不允许超过 max_prompt_length。如果抛出错误，用户应增加 max_prompt_length。您还可以设置 <code class="docutils literal notranslate"><span class="pre">left</span></code> 和 <code class="docutils literal notranslate"><span class="pre">right</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.image_key</span></code>: 多模态数据集中图像所在的字段。默认值为 'images'。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.trust_remote_code</span></code>: 如果远程分词器有 Python 文件，我们可以使用此字段来允许使用远程分词器。例如：moonshotai/Moonlight-16B-A3B-Instruct</p></li>
</ul>
</section>
<section id="id3">
<h3>定制数据集<a class="headerlink" href="#id3" title="Link to this heading"></a></h3>
<p>定制数据集扩展已为SFT训练器实现，并可以通过类似的更改扩展到其他训练器。</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">custom_cls</span><span class="p">:</span>
<span class="w">  </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data.custom_cls.path</span></code>: 包含您定制数据集类的文件路径。如果未指定，将使用预先实现的数据集。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.custom_cls.name</span></code>: 指定文件中数据集类的名称。</p></li>
</ul>
</section>
<section id="id4">
<h3>演员/回放/参考策略<a class="headerlink" href="#id4" title="Link to this heading"></a></h3>
<p><a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a>yaml
actor_rollout_ref:</p>
<blockquote>
<div><p>hybrid_engine: True
model:</p>
<blockquote>
<div><p>path: ~/models/deepseek-llm-7b-chat
external_lib: null
override_config:</p>
<blockquote>
<div><p>model_config: {}
moe_config:  # 仅适用于Megatron，可以调整moe配置</p>
<blockquote>
<div><p>freeze_moe_router: False  # 仅适用于Megatron，可以冻结moe路由器（无梯度）</p>
</div></blockquote>
</div></blockquote>
<p>enable_gradient_checkpointing: False
enable_activation_offload: False
trust_remote_code: False
use_remove_padding: False</p>
</div></blockquote>
<dl>
<dt>actor:</dt><dd><p>strategy: fsdp  # 这是为了向后兼容
ppo_mini_batch_size: 256
ppo_micro_batch_size: null # 将被弃用，请使用ppo_micro_batch_size_per_gpu
ppo_micro_batch_size_per_gpu: 8
use_dynamic_bsz: False
ppo_max_token_len_per_gpu: 16384 # n * ${data.max_prompt_length} + ${data.max_response_length}
grad_clip: 1.0
clip_ratio: 0.2
entropy_coeff: 0.0
use_kl_loss: False # 对于GRPO为True
use_torch_compile: True # False以禁用torch编译
kl_loss_coef: 0.001 # 对于grpo
kl_loss_type: low_var_kl # 对于grpo
ppo_epochs: 1
data_loader_seed: null
shuffle: False
ulysses_sequence_parallel_size: 1 # sp大小
optim:</p>
<blockquote>
<div><p>lr: 1e-6
lr_warmup_steps: -1 # 优先级。负值表示委托给lr_warmup_steps_ratio。
lr_warmup_steps_ratio: 0.  # 总步数将在运行时注入
min_lr_ratio: 0.0   # 仅与余弦学习率调度器一起使用，默认为0.0
num_cycles: 0.5     # 仅与余弦学习率调度器一起使用，默认为0.5
warmup_style: constant  # 从constant/cosine中选择
total_training_steps: -1  # 必须由程序覆盖</p>
</div></blockquote>
<dl>
<dt>fsdp_config:</dt><dd><dl class="simple">
<dt>wrap_policy:</dt><dd><p># transformer_layer_cls_to_wrap: None
min_num_params: 0</p>
</dd>
</dl>
<p>param_offload: False
optimizer_offload: False
fsdp_size: -1</p>
</dd>
<dt>checkpoint:</dt><dd><p># 保存检查点时包含的内容
# 使用'hf_model'可以将整个模型保存为hf格式，现在仅使用分片模型检查点以节省空间
save_contents: ['model', 'optimizer', 'extra']
# 为了更大的灵活性，您可以指定从检查点加载的内容。
load_contents: ${actor_rollout_ref.actor.checkpoint.save_contents}</p>
</dd>
</dl>
</dd>
<dt>ref:</dt><dd><dl>
<dt>fsdp_config:</dt><dd><p>param_offload: False
wrap_policy:</p>
<blockquote>
<div><p># transformer_layer_cls_to_wrap: None
min_num_params: 0</p>
</div></blockquote>
</dd>
</dl>
<p>log_prob_micro_batch_size: null # 将被弃用，请使用log_prob_micro_batch_size_per_gpu
log_prob_micro_batch_size_per_gpu: 16
log_prob_use_dynamic_bsz: ${actor_rollout_ref.actor.use_dynamic_bsz}
log_prob_max_token_len_per_gpu: ${actor_rollout_ref.actor.ppo_max_token_len_per_gpu}
ulysses_sequence_parallel_size: ${actor_rollout_ref.actor.ulysses_sequence_parallel_size} # sp大小</p>
</dd>
<dt>rollout:</dt><dd><p>name: vllm
temperature: 1.0
top_k: -1 # 0表示hf rollout，-1表示vllm rollout
top_p: 1
prompt_length: ${data.max_prompt_length}  # 不用于开源
response_length: ${data.max_response_length}
# 对于vllm rollout
dtype: bfloat16 # 应与FSDP对齐
gpu_memory_utilization: 0.5
ignore_eos: False
enforce_eager: True
free_cache_engine: True
load_format: dummy_dtensor
tensor_model_parallel_size: 2
max_num_batched_tokens: 8192
max_num_seqs: 1024
log_prob_micro_batch_size: null # 将被弃用，请使用log_prob_micro_batch_size_per_gpu
log_prob_micro_batch_size_per_gpu: 16
log_prob_use_dynamic_bsz: ${actor_rollout_ref.actor.use_dynamic_bsz}
log_prob_max_token_len_per_gpu: ${actor_rollout_ref.actor.ppo_max_token_len_per_gpu}
# 对于hf rollout
do_sample: True
engine_kwargs: # 推理引擎参数</p>
<blockquote>
<div><dl class="simple">
<dt>vllm:</dt><dd><p>swap_space: null # null表示“使用引擎默认值”（通常为4 GB），将其设置为，例如，32表示32 GB
disable_mm_preprocessor_cache: False # 禁用多模型模型的预处理器缓存</p>
</dd>
<dt>sglang:</dt><dd><p>attention_backend: null # null表示使用引擎默认值，可用选项：flashinfer, triton, flashmla</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
</div></blockquote>
<p><a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a></p>
<p><a href="#id13"><span class="problematic" id="id14">``</span></a>`
n: 1 # 对于每个提示，采样 n 个响应（即样本次数）。将其设置为大于 1 的值以进行 grpo、rloo</p>
<blockquote>
<div><dl class="simple">
<dt>val_kwargs:</dt><dd><p># 验证的采样参数
top_k: -1 # 0 表示 hf rollout，-1 表示 vllm rollout
top_p: 1.0
temperature: 0
n: 1
do_sample: False # 默认在验证时为 eager</p>
</dd>
<dt>agent:</dt><dd><dl class="simple">
<dt>custom_async_server: # 使用自定义异步服务器实现进行 rollout</dt><dd><p>path: null
name: null</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<p><strong>演员、rollout 和参考模型的通用配置</strong>
<a href="#id15"><span class="problematic" id="id16">``</span></a><a href="#id17"><span class="problematic" id="id18">`</span></a></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.hybrid_engine</span></code>: 是否使用混合引擎，目前仅支持混合引擎</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.model.path</span></code>: Huggingface 模型路径。这可以是本地路径或 HDFS 路径。对于 HDFS 路径，我们提供工具将其下载到 DRAM 并将 HDFS 路径转换为本地路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.model.external_libs</span></code>: 需要导入的额外 Python 包。用于将模型或分词器注册到 Huggingface 系统中。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.model.override_config</span></code>: 用于覆盖模型的一些原始配置，主要是 dropout。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.model.enable_gradient_checkpointing</span></code>: 是否为 actor 启用梯度检查点。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.model.enable_activation_offload</span></code>: 是否为 actor 启用激活卸载。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.model.trust_remote_code</span></code>: 是否启用加载远程代码模型。</p></li>
</ul>
<p><strong>演员模型</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.strategy</span></code>: fsdp 或 megatron。在这个例子中，我们使用 fsdp 后端。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.ppo_mini_batch_size</span></code>: 一个样本被拆分为多个子批次，批次大小为 ppo_mini_batch_size，用于 PPO 更新。ppo_mini_batch_size 是所有工作节点/ GPU 的全局数量。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.ppo_micro_batch_size</span></code>: [将被弃用，请使用 ppo_micro_batch_size_per_gpu] 类似于梯度累积，单次前向传播的 micro_batch_size_per_gpu，权衡速度与 GPU 内存。该值表示全局视图。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu</span></code>: 类似于梯度累积，单次前向传播的 micro_batch_size_per_gpu，权衡速度与 GPU 内存。该值表示每个 GPU 的本地数量。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.grad_clip</span></code>: 用于演员更新的梯度裁剪。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.use_kl_loss</span></code>: 在演员中使用 KL 损失。当使用时，我们不在奖励函数中应用 KL。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.clip_ratio</span></code>: PPO 裁剪比率。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.use_torch_compile</span></code>: 是否在演员中使用 torch 编译。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.entropy_coeff</span></code>: 计算PPO损失时的熵权重。默认值自v0.3.x起更改为0.0。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.ppo_epochs</span></code>: 在一组采样数据上进行PPO更新的轮数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.data_loader_seed</span></code>: 从torch 2.6.0开始，Megatron后端可能会获取由pytorch在cp排名之间生成的错误种子，从而导致这些排名之间的数据不对齐，因此我们需要手动设置种子以避免挂起问题。如果``actor_rollout_ref.actor.shuffle``不为null，则必须设置此项。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.shuffle</span></code>: 当有多个轮次时，是否对数据进行洗牌。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.optim</span></code>: Actor的优化器参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.fsdp_config</span></code>: Actor训练的FSDP配置。</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">wrap_policy</span></code>: FSDP包装策略。默认使用Huggingface的包装策略，即通过DecoderLayer进行包装。</p>
<ul>
<li><p>不需要设置transformer_layer_cls_to_wrap，因此我们将其注释掉。</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">*_offload</span></code>: 是否启用参数、梯度和优化器的卸载。</p>
<ul>
<li><p>以速度换取GPU内存。</p></li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.use_kl_loss</span></code>: 是否启用 KL 损失。默认值为 False。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.kl_loss_coef</span></code>: KL 损失的系数。默认值为 0.001。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.kl_loss_type</span></code>: 支持 <code class="docutils literal notranslate"><span class="pre">kl</span></code> (<code class="docutils literal notranslate"><span class="pre">k1</span></code>)、<code class="docutils literal notranslate"><span class="pre">abs</span></code>、<code class="docutils literal notranslate"><span class="pre">mse</span></code> (<code class="docutils literal notranslate"><span class="pre">k2</span></code>)、<code class="docutils literal notranslate"><span class="pre">low_var_kl</span></code> (<code class="docutils literal notranslate"><span class="pre">k3</span></code>) 和 <code class="docutils literal notranslate"><span class="pre">full</span></code>。用于计算演员与参考策略之间的 KL 散度。有关具体选项，请参阅 <cite>kl_penalty()</cite> 在 <a class="reference external" href="https://github.com/volcengine/verl/blob/main/verl/trainer/ppo/core_algos.py">core_algos.py</a> 中。有关详细分析，请参阅此博客文章：<a class="reference external" href="http://joschu.net/blog/kl-approx.html">http://joschu.net/blog/kl-approx.html</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.checkpoint</span></code>: 演员中检查点功能的配置</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">save_contents</span></code>: 在检查点中保存的内容。默认情况下，我们在检查点中保存模型、优化器和额外信息。
额外信息目前包括 Rng 状态、FSDP 支持的 lr_scheduler，以及即将推出的 Megatron opt_param_scheduler。
默认情况下，我们不在检查点中存储 hf_model，但我们在 <code class="docutils literal notranslate"><span class="pre">scripts/model_merge.py</span></code> 中提供了一个工具，将检查点格式转换为 hf 格式。</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">load_contents</span></code>：要在检查点中加载的内容，您可以指定不同的检查点加载内容。默认情况下，它与 <code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code> 相同。</p></li>
</ul>
<p><strong>参考模型</strong></p>
<p>参考模型将在 <code class="docutils literal notranslate"><span class="pre">actor.use_kl_loss</span></code> 或/和 <code class="docutils literal notranslate"><span class="pre">algorithm.use_kl_in_reward</span></code> 为 True 时启用。</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.ref</span></code>: FSDP 配置与 actor 相同。<strong>对于大于 7B 的模型，建议默认开启 ref 的 offload</strong></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.ref.log_prob_micro_batch_size</span></code>: [将被弃用，请使用 log_prob_micro_batch_size_per_gpu] 在计算 <code class="docutils literal notranslate"><span class="pre">ref_log_prob</span></code> 时，单次前向传播的批量大小。该值表示全局数量。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu</span></code>: 在计算 <code class="docutils literal notranslate"><span class="pre">ref_log_prob</span></code> 时，单次前向传播的批量大小。该值表示每个 GPU 的本地数量。</p></li>
</ul>
<p><strong>推广模型</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.name</span></code>: hf/vllm/sglang.</p></li>
<li><p>Rollout (自回归) 参数。键应与 vLLM 的 <code class="docutils literal notranslate"><span class="pre">SamplingParams</span></code> 中的属性名称相等。</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">temperature</span></code>、<code class="docutils literal notranslate"><span class="pre">top_k</span></code>、<code class="docutils literal notranslate"><span class="pre">top_p</span></code> 等：<code class="docutils literal notranslate"><span class="pre">SamplingParams</span></code> 中的采样参数。</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.dtype</span></code>: Rollout 模型参数类型。这应与 FSDP/Megatron 后端中的 actor 模型参数类型对齐。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.gpu_memory_utilization</span></code>:</p></li>
<li><p>对于 vLLM v0.7.0 及更高版本：用于 vLLM 实例的 <strong>总</strong> GPU 内存的比例。
- 对于 SGLang：对应于 <code class="docutils literal notranslate"><span class="pre">mem_fraction_static</span></code>，用于 <strong>静态</strong> 内存（如模型权重和 KV 缓存）的空闲 GPU 内存的比例。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.tensor_model_parallel_size</span></code>：用于 rollout 的 TP 大小。仅对 vllm 有效。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.log_prob_micro_batch_size</span></code>：[将被弃用，请使用 log_prob_micro_batch_size_per_gpu] 在计算 <code class="docutils literal notranslate"><span class="pre">log_prob</span></code> 时一次前向传播的批量大小。该值表示全局数量。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu</span></code>：每个 GPU 的微批量大小（一次前向传播的批量大小），用于重新计算 <code class="docutils literal notranslate"><span class="pre">log_prob</span></code>。该值表示每个 GPU 的本地数量。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.do_sample</span></code>：在训练 rollout 期间是否进行采样。如果设置为 False，rollout 模型将执行贪婪采样。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.val_kwargs</span></code>：在验证期间专门使用的采样参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">top_k</span></code>: Top-k 采样参数。默认值为 -1（用于 vLLM rollout）或 0（用于 HF rollout）。
- <code class="docutils literal notranslate"><span class="pre">top_p</span></code>: Top-p 采样参数。默认值为 1.0（禁用）。
- <code class="docutils literal notranslate"><span class="pre">temperature</span></code>: 采样温度。默认值为 0（确定性贪婪）。
- <code class="docutils literal notranslate"><span class="pre">n</span></code>: 在验证期间生成的响应数量。默认值为 1。
- <code class="docutils literal notranslate"><span class="pre">do_sample</span></code>: 在验证期间是否使用采样。默认值为 False（确定性输出）。当设置为 True 时，rollout 将使用 <code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.val_kwargs</span></code> 参数（top_k、top_p、temperature）来控制采样行为。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.engine_kwargs.vllm</span></code>: 额外的 vllm 引擎参数</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">swap_space</span></code>: 推理引擎使用的交换空间（以 GB 为单位）。正整数，例如，<code class="docutils literal notranslate"><span class="pre">32</span></code> 表示 32 GB。<code class="docutils literal notranslate"><span class="pre">null</span></code>: 表示不设置并使用引擎默认值（通常，例如，vLLM 的默认值为 4 GB）。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">disable_mm_preprocessor_cache</span></code>: 是否禁用多模型的预处理器缓存。</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.engine_kwargs.sglang</span></code>: 额外的 sglang 引擎参数</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">attention_backend</span></code>: 用于推理引擎的注意力后端。</p></li>
</ul>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">null</span></code>: 表示不设置并使用引擎的默认值（通常，例如，<code class="docutils literal notranslate"><span class="pre">fa3</span></code> 用于 SGLang）</dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">flashinfer</span></code>: 使用 flashinfer 注意力后端。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">triton</span></code>: 使用 triton 注意力后端。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">flashmla</span></code>: 使用 flashmla 注意力后端。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.ignore_eos</span></code>: 是否忽略 EOS
令牌，并在生成 EOS 令牌后继续生成令牌。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.free_cache_engine</span></code>: 在 rollout 生成阶段后卸载 KVCache。
默认值为 True。当设置为 True 时，对于 vllm v0.5.4 和 v0.6.3，我们需要禁用 CUDAGraph 的使用
（将 <code class="docutils literal notranslate"><span class="pre">enforce_eager</span></code> 设置为 True。）</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.enforce_eager</span></code>: 是否在 vLLM 生成中使用 CUDAGraph。
默认设置为 True，以禁用 CUDAGraph。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.rollout.load_format</span></code>: 使用哪个权重加载器
将 actor 模型权重加载到 rollout 模型中。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">auto</span></code>: 使用 Megatron 权重加载器。
- <code class="docutils literal notranslate"><span class="pre">megatron</span></code>: 使用 Megatron 权重加载器。与 Megatron 后端一起部署。输入模型 <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> 已经沿 TP 维度进行了分区，并且已经沿 PP 维度进行了聚合。此权重加载器要求 Rollout 模型和 Actor 模型的参数形状和名称必须相同。
- <code class="docutils literal notranslate"><span class="pre">dtensor</span></code>: 使用 Huggingface 权重加载器时的默认解决方案。与 FSDP 后端一起部署，且 state_dict_type 为 <code class="docutils literal notranslate"><span class="pre">StateDictType.SHARDED_STATE_DICT</span></code>。推荐使用此权重加载器。
- <code class="docutils literal notranslate"><span class="pre">hf</span></code>: 使用 Huggingface 权重加载器。与 FSDP 后端一起部署，且 state_dict_type 为 <code class="docutils literal notranslate"><span class="pre">StateDictType.FULL_STATE_DICT</span></code>。此解决方案不需要为 vLLM 中实现的每个模型重写权重加载器，但会导致更大的峰值内存使用。
- <code class="docutils literal notranslate"><span class="pre">dummy_hf</span></code>, <code class="docutils literal notranslate"><span class="pre">dummy_megatron</span></code>, <code class="docutils literal notranslate"><span class="pre">dummy_dtensor</span></code>: 随机初始化。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p><strong>注意</strong>: 在此配置字段中，用户只需从 <code class="docutils literal notranslate"><span class="pre">dummy_megatron</span></code>、<code class="docutils literal notranslate"><span class="pre">dummy_dtensor</span></code>、<code class="docutils literal notranslate"><span class="pre">dummy_hf</span></code> 中选择用于回放初始化，我们的混合引擎将在演员/回放权重同步期间选择相应的权重加载器（即 <code class="docutils literal notranslate"><span class="pre">megatron</span></code>、<code class="docutils literal notranslate"><span class="pre">dtensor</span></code>、<code class="docutils literal notranslate"><span class="pre">hf</span></code>）。</p>
</div>
<section id="megatron">
<h4>Megatron 优化器和优化器参数调度器<a class="headerlink" href="#megatron" title="Link to this heading"></a></h4>
<p><a href="#id19"><span class="problematic" id="id20">``</span></a><a href="#id21"><span class="problematic" id="id22">`</span></a>yaml
optim:</p>
<blockquote>
<div><p>optimizer: adam
lr: 1e-6
clip_grad: 1.0
total_training_steps: -1  # 必须由程序覆盖
lr_warmup_init: 0.0  # 预热的初始学习率，默认为0.0
lr_warmup_steps: -1 # 优先级。负值意味着委托给 lr_warmup_steps_ratio。
lr_warmup_steps_ratio: 0.  # 在运行时将注入的总步骤
lr_decay_steps: null
lr_decay_style: constant # 从 constant/linear/cosine/inverse_square_root 中选择
min_lr: 0.0 # 最小学习率，默认为0.0
weight_decay: 0.01
weight_decay_incr_style: constant # 从 constant/linear/cosine 中选择
lr_wsd_decay_style: exponential # 从 constant/exponential/cosine 中选择
lr_wsd_decay_steps: null
use_checkpoint_opt_param_scheduler: False # 使用检查点优化器参数调度器</p>
</div></blockquote>
<p>注意，Megatron 优化器和 FSDP 优化器之间的 API 存在一些差异。
<a href="#id23"><span class="problematic" id="id24">``</span></a><a href="#id25"><span class="problematic" id="id26">`</span></a></p>
<ul class="simple">
<li><p>Megatron 优化器调度器将 lr_warmup 之后的周期命名为 lr_decay_steps，因此 <code class="docutils literal notranslate"><span class="pre">warmup_style</span></code> 实际上指的是 warmup 之后的学习率衰减方式。</p></li>
<li><p>Megatron 优化器还支持权重衰减机制。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_checkpoint_opt_param_scheduler</span></code> 决定是否使用检查点优化器参数调度器。如果设置为 True，优化器参数调度器将在检查点中保存，并在恢复训练时从检查点加载。</p></li>
</ul>
<p>对于学习率衰减，原始 Megatron 预训练的默认选项 <code class="docutils literal notranslate"><span class="pre">lr_decay_style</span></code> 为 <code class="docutils literal notranslate"><span class="pre">linear</span></code>，这意味着学习率将在 <code class="docutils literal notranslate"><span class="pre">lr_decay_steps</span></code> 内从初始学习率线性衰减到 <code class="docutils literal notranslate"><span class="pre">min_lr</span></code>。然而，在 verl 中，为了与 FSDP 的默认行为保持一致，我们将默认的 <code class="docutils literal notranslate"><span class="pre">lr_decay_style</span></code> 设置为 <code class="docutils literal notranslate"><span class="pre">constant</span></code>，这意味着学习率将在 warmup 阶段后保持不变。</p>
</section>
</section>
<section id="critic">
<h3>Critic 模型<a class="headerlink" href="#critic" title="Link to this heading"></a></h3>
<p>Critic 的大多数参数与 Actor 模型相似。</p>
</section>
<section id="reward">
<h3>Reward 模型<a class="headerlink" href="#reward" title="Link to this heading"></a></h3>
<dl>
<dt>reward_model:</dt><dd><p>enable: False
model:</p>
<blockquote>
<div><p>input_tokenizer: ${actor_rollout_ref.model.path}  # 如果聊天模板相同，请将其设置为null
path: ~/models/Anomy-RM-v0.1
external_lib: ${actor_rollout_ref.model.external_lib}
trust_remote_code: False
fsdp_config:</p>
<blockquote>
<div><p>min_num_params: 0
param_offload: False</p>
</div></blockquote>
</div></blockquote>
<p>micro_batch_size_per_gpu: 16
max_length: null
reward_manager: naive</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">reward_model.enable</span></code>: 是否启用奖励模型。如果为False，我们仅使用用户定义的奖励函数来计算奖励。在GSM8K和数学示例中，我们禁用奖励模型。对于使用full_hh_rlhf的RLHF对齐示例，我们利用奖励模型来评估响应。如果为False，以下参数将无效。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reward_model.model</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_tokenizer</span></code>: 输入分词器。如果奖励模型的聊天模板与策略不一致，我们需要先解码为明文，然后应用奖励模型的聊天模板。接着使用奖励模型进行评分。如果聊天模板一致，可以设置为 null。
- <code class="docutils literal notranslate"><span class="pre">path</span></code>: 奖励模型的 HDFS 路径或本地路径。请注意，奖励模型仅支持 AutoModelForSequenceClassification。其他模型类型需要定义自己的 RewardModelWorker 并从代码中传递。
- <code class="docutils literal notranslate"><span class="pre">trust_remote_code</span></code>: 是否启用加载远程代码模型，默认为 False。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reward_model.reward_manager</span></code>: 奖励管理器。这定义了基于规则的奖励计算机制以及处理不同奖励来源的方式。默认值为 <code class="docutils literal notranslate"><span class="pre">naive</span></code>。如果所有验证函数都是多进程安全的，奖励管理器可以设置为 <code class="docutils literal notranslate"><span class="pre">prime</span></code> 以进行并行验证。</p></li>
</ul>
</section>
<section id="id27">
<h3>自定义奖励函数<a class="headerlink" href="#id27" title="Link to this heading"></a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">custom_reward_function</span><span class="p">:</span>
<span class="w">  </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">compute_score</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">custom_reward_function.path</span></code>：包含您自定义奖励函数的文件路径。如果未指定，将使用预先实现的奖励函数。</p></li>
<li><p><a href="#id28"><span class="problematic" id="id29">``</span></a>custom_reward_function.name``（可选）：指定文件中奖励函数的名称。默认值为 'compute_score'。</p></li>
</ul>
</section>
<section id="id30">
<h3>算法<a class="headerlink" href="#id30" title="Link to this heading"></a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">algorithm</span><span class="p">:</span>
<span class="w">  </span><span class="nt">gamma</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">  </span><span class="nt">lam</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">  </span><span class="nt">adv_estimator</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gae</span>
<span class="w">  </span><span class="nt">use_kl_in_reward</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">  </span><span class="nt">kl_penalty</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kl</span><span class="w">  </span><span class="c1"># 如何估计kl散度</span>
<span class="w">  </span><span class="nt">kl_ctrl</span><span class="p">:</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fixed</span>
<span class="w">    </span><span class="nt">kl_coef</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.005</span>
<span class="w">    </span><span class="nt">horizon</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10000</span>
<span class="w">    </span><span class="nt">target_kl</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">gamma</span></code>: 折扣因子</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lam</span></code>: GAE估计器中偏差和方差之间的权衡</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">adv_estimator</span></code>: 支持 <code class="docutils literal notranslate"><span class="pre">gae</span></code>、<code class="docutils literal notranslate"><span class="pre">grpo</span></code>、<code class="docutils literal notranslate"><span class="pre">reinforce_plus_plus</span></code>、<code class="docutils literal notranslate"><span class="pre">reinforce_plus_plus_baseline</span></code>、<code class="docutils literal notranslate"><span class="pre">rloo</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_kl_in_reward</span></code>: 是否启用奖励中的kl惩罚。默认值为False。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kl_penalty</span></code>: 支持 <code class="docutils literal notranslate"><span class="pre">kl</span></code>、<code class="docutils literal notranslate"><span class="pre">abs</span></code>、<code class="docutils literal notranslate"><span class="pre">mse</span></code>、<code class="docutils literal notranslate"><span class="pre">low_var_kl</span></code> 和 <code class="docutils literal notranslate"><span class="pre">full</span></code>。如何计算演员和参考策略之间的kl散度。有关具体选项，请参阅 <cite>kl_penalty()</cite> 在 <a class="reference external" href="https://github.com/volcengine/verl/blob/main/verl/trainer/ppo/core_algos.py">core_algos.py</a> 中的说明。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kl_ctrl</span></code>: 奖励中kl惩罚控制器的配置
- <code class="docutils literal notranslate"><span class="pre">kl_coef</span></code>: 奖励中kl惩罚的（初始）系数。默认值为0.001。
- <code class="docutils literal notranslate"><span class="pre">type</span></code>: 'fixed' 表示固定的KL控制器，'adaptive' 表示自适应的KL控制器。
- <code class="docutils literal notranslate"><span class="pre">horizon</span></code> 和 <code class="docutils literal notranslate"><span class="pre">target_kl</span></code>: 有关详细信息，请参阅自适应KL控制器的源代码。</p></li>
</ul>
</section>
<section id="id32">
<h3>训练器<a class="headerlink" href="#id32" title="Link to this heading"></a></h3>
<p><a href="#id33"><span class="problematic" id="id34">``</span></a><a href="#id35"><span class="problematic" id="id36">`</span></a>yaml
trainer:</p>
<blockquote>
<div><p>total_epochs: 30
project_name: verl_examples
experiment_name: gsm8k
logger: ['console', 'wandb']
log_val_generations: 0
nnodes: 1
n_gpus_per_node: 8
save_freq: -1
val_before_train: True
test_freq: 2
critic_warmup: 0
default_hdfs_dir: ~/experiments/gsm8k/ppo/${trainer.experiment_name} # hdfs检查点路径
default_local_dir: checkpoints/${trainer.project_name}/${trainer.experiment_name} # 本地检查点路径
resume_mode: auto # 或者disable或者resume_path（如果设置了resume_from_path）
resume_from_path: null
remove_previous_ckpt_in_save: False
del_local_ckpt_after_load: False
ray_wait_register_center_timeout: 300</p>
</div></blockquote>
<p><a href="#id37"><span class="problematic" id="id38">``</span></a><a href="#id39"><span class="problematic" id="id40">`</span></a></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.total_epochs</span></code>: 训练中的总epoch数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.project_name</span></code>: 用于wandb、swanlab、mlflow的项目名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.experiment_name</span></code>: 用于wandb、swanlab、mlflow的实验名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.logger</span></code>: 支持控制台以及wandb、swanlab、mlflow、tensorboard。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.log_val_generations</span></code>: 在验证期间记录的代数数量（默认为``0``）。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.nnodes</span></code>: 训练中使用的节点数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.n_gpus_per_node</span></code>: 每个节点的GPU数量。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.save_freq</span></code>: 保存actor和critic模型检查点的频率（按迭代计算）。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.val_before_train</span></code>: 是否在训练之前运行验证。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.test_freq</span></code>: 验证频率（按迭代计算）。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.critic_warmup</span></code>: 在实际策略学习之前训练评论者模型的迭代次数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.resume_mode</span></code>: 恢复训练的模式。支持``disable``、<code class="docutils literal notranslate"><span class="pre">auto``和``resume_path</span></code>。如果设置为默认的``auto``，程序将自动从``default_local_dir``中的最新检查点恢复。如果设置为``resume_path``，程序将从``resume_from_path``指定的路径恢复。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.resume_from_path</span></code>: 恢复训练的路径。仅在``resume_mode``设置为``resume_path``时有效。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.remove_previous_ckpt_in_save</span></code>: 是否删除保存目录中的先前检查点。默认为False。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.del_local_ckpt_after_load</span></code>: 是否在加载后删除本地检查点。默认为False。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.ray_wait_register_center_timeout</span></code>: 等待ray注册中心准备就绪的超时时间。默认为300秒。</p></li>
</ul>
<p>这幅图示了配置对训练的影响。</p>
<p><a class="reference external" href="https://excalidraw.com/#json=pfhkRmiLm1jnnRli9VFhb,Ut4E8peALlgAUpr7E5pPCA">https://excalidraw.com/#json=pfhkRmiLm1jnnRli9VFhb,Ut4E8peALlgAUpr7E5pPCA</a></p>
<img alt="https://github.com/user-attachments/assets/16aebad1-0da6-4eb3-806d-54a74e712c2d" src="https://github.com/user-attachments/assets/16aebad1-0da6-4eb3-806d-54a74e712c2d" />
</section>
</section>
<section id="evaluation-yaml">
<h2>evaluation.yaml<a class="headerlink" href="#evaluation-yaml" title="Link to this heading"></a></h2>
<p>评估配置文件(evaluation.yaml)用于定义评估任务的相关参数和设置。在这个文件中，您可以指定评估任务的数据集、评估指标、评估频率等。以下是一个示例评估配置文件的结构：</p>
<p><a href="#id41"><span class="problematic" id="id42">``</span></a><a href="#id43"><span class="problematic" id="id44">`</span></a>yaml
evaluation:</p>
<blockquote>
<div><p>dataset: data/evaluation_dataset.csv
metrics:</p>
<blockquote>
<div><ul class="simple">
<li><p>accuracy</p></li>
<li><p>precision</p></li>
<li><p>recall</p></li>
</ul>
</div></blockquote>
<p>frequency: daily</p>
</div></blockquote>
<p><a href="#id45"><span class="problematic" id="id46">``</span></a><a href="#id47"><span class="problematic" id="id48">`</span></a></p>
<p>在这个示例中，评估配置文件指定了评估任务使用的数据集为&quot;data/evaluation_dataset.csv&quot;，评估指标包括准确率、精确率和召回率，评估频率为每天一次。您可以根据实际需求修改这些参数以满足您的评估任务要求。</p>
<section id="id49">
<h3>数据<a class="headerlink" href="#id49" title="Link to this heading"></a></h3>
<p><a href="#id50"><span class="problematic" id="id51">``</span></a><a href="#id52"><span class="problematic" id="id53">`</span></a>yaml
数据:</p>
<blockquote>
<div><p>路径: /tmp/math_Qwen2-7B-Instruct.parquet
提示键: prompt
响应键: responses
数据源键: data_source
奖励模型键: reward_model</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data.path</span></code>: 数据集文件的路径（Parquet格式）。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.prompt_key</span></code>: 数据集中包含提示的字段。默认为'prompt'。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.response_key</span></code>: 该键保存生成的响应。这应该是表示响应的字符串列表。默认为'responses'。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.data_source_key</span></code>: 用于区分不同数据源的度量计算，确保为每个源独立计算度量。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data.reward_model_key</span></code>: 该键保存参考答案。这些参考答案通常用作任务的基准或测试用例。</p></li>
</ul>
</section>
<section id="id54">
<h3>自定义奖励函数<a class="headerlink" href="#id54" title="Link to this heading"></a></h3>
<p><a href="#id55"><span class="problematic" id="id56">``</span></a><a href="#id57"><span class="problematic" id="id58">`</span></a>yaml
自定义奖励函数:</p>
<blockquote>
<div><p>路径: null
名称: compute_score</p>
</div></blockquote>
<p><a href="#id59"><span class="problematic" id="id60">``</span></a><a href="#id61"><span class="problematic" id="id62">`</span></a></p>
<p><a href="#id63"><span class="problematic" id="id64">``</span></a><a href="#id65"><span class="problematic" id="id66">`</span></a>rst
sft_trainer.yaml for SFT FSDP 后端</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">custom_reward_function.path</span></code>: 自定义奖励函数文件的路径。如果未指定，将使用预先实现的奖励函数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">custom_reward_function.name</span></code> (可选) : 指定文件中的奖励函数的名称。默认值为'compute_score'。</p></li>
</ul>
<p><a href="#id67"><span class="problematic" id="id68">``</span></a><a href="#id69"><span class="problematic" id="id70">`</span></a></p>
<p>优化器</p>
<p><a href="#id71"><span class="problematic" id="id72">``</span></a><a href="#id73"><span class="problematic" id="id74">`</span></a>yaml
优化器配置:</p>
<blockquote>
<div><p>学习率: 1e-5
权重衰减: 0.01
热身步数比例: 0.1
梯度裁剪: 1.0
学习率调度器: 余弦</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">optim.lr</span></code>: 优化器的学习率。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optim.weight_decay</span></code>: 优化器的权重衰减。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optim.warmup_steps_ratio</span></code>: 热身步数占总训练步数的比例。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optim.clip_grad</span></code>: 梯度裁剪值。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optim.lr_scheduler</span></code>: 学习率调度器类型。选项:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">cosine</span></code>: 余弦学习率调度器带有热身（默认）。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">wsd</span></code>: 热身稳定衰减调度器，在热身和衰减阶段之间提供稳定的学习率阶段。</p></li>
</ul>
</li>
</ul>
<p><a href="#id75"><span class="problematic" id="id76">``</span></a><a href="#id77"><span class="problematic" id="id78">`</span></a></p>
</section>
<section id="id79">
<h3>模型<a class="headerlink" href="#id79" title="Link to this heading"></a></h3>
<p>大多数Model的参数与Reward Model类似。</p>
<p><a href="#id80"><span class="problematic" id="id81">``</span></a><a href="#id82"><span class="problematic" id="id83">`</span></a>yaml
model:</p>
<blockquote>
<div><p>partial_pretrain: ~/models/gemma-1.1-7b-it
fsdp_config:</p>
<blockquote>
<div><p>model_dtype: fp32
wrap_policy:</p>
<blockquote>
<div><p>min_num_params: 0</p>
</div></blockquote>
<p>cpu_offload: False
offload_params: False</p>
</div></blockquote>
<p>external_lib: null
enable_gradient_checkpointing: False
trust_remote_code: False
lora_rank: 0
lora_alpha: 16
target_modules: all-linear
use_liger: False</p>
</div></blockquote>
<p><a href="#id84"><span class="problematic" id="id85">``</span></a><a href="#id86"><span class="problematic" id="id87">`</span></a></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">partial_pretrain</span></code>: 预训练模型的HDFS路径或本地路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fsdp_config</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">model_dtype</span></code>: 模型参数类型，默认为``fp32``。
支持：<code class="docutils literal notranslate"><span class="pre">bf16</span></code>，<code class="docutils literal notranslate"><span class="pre">fp16</span></code>，<code class="docutils literal notranslate"><span class="pre">fp32</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cpu_offload</span></code>: 是否为FSDP启用CPU卸载。如果为True，
将使用offload_params作为参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">offload_params</span></code>: 是否将参数卸载到CPU
当未参与计算时。如果为True，则将梯度也卸载到CPU，这意味着优化器步骤在CPU上运行。</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">lora_rank</span></code>: LoRA模型的秩， 默认值为0。如果 <code class="docutils literal notranslate"><span class="pre">lora_rank</span></code>&gt;0，我们将训练LoRA模块而不是调整整个模型。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lora_alpha</span></code>: LoRA缩放的alpha参数，默认值为16。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">target_modules</span></code>: 要应用适配器的模块名称，默认为 <code class="docutils literal notranslate"><span class="pre">all-linear</span></code>。详细信息请参见`peft文档 &lt;<a class="reference external" href="https://huggingface.co/docs/peft/v0.15.0/zh/package_reference/lora#peft.LoraConfig.target_modules">https://huggingface.co/docs/peft/v0.15.0/zh/package_reference/lora#peft.LoraConfig.target_modules</a>&gt;`_。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_liger</span></code>: 是否启用Liger内核，默认为False。如果为True，我们将在模型上应用Liger内核（取决于 <cite>liger-kernel</cite>）。</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="页脚">
        <a href="../start/more_resources.html" class="btn btn-neutral float-left" title="更多资源" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="../algo/ppo.html" class="btn btn-neutral float-right" title="近端策略优化 (PPO)" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2024 ByteDance Seed Foundation MLSys Team。</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用的 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a> 开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>