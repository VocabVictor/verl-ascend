#!/usr/bin/env python3
"""
å¼‚æ­¥ç‰ˆæ–‡æ¡£ç¿»è¯‘è„šæœ¬ - ä½¿ç”¨å¼‚æ­¥æœºåˆ¶å’Œhttpxå®¢æˆ·ç«¯
è§£å†³SSLé—®é¢˜å’Œç¿»è¯‘è´¨é‡é—®é¢˜

æ–°ç‰¹æ€§ï¼š
1. ä½¿ç”¨OpenAIå®¢æˆ·ç«¯å’Œhttpxç¦ç”¨SSLéªŒè¯
2. å¼‚æ­¥ç¿»è¯‘æœºåˆ¶æé«˜æ•ˆç‡
3. æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
4. å¼ºåˆ¶é‡æ–°ç¿»è¯‘ä¸å®Œæ•´çš„æ–‡ä»¶
"""

import os
import sys
import asyncio
import time
from pathlib import Path
from typing import List, Dict, Optional
from dotenv import load_dotenv
import httpx
from openai import AsyncOpenAI

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class AsyncDocumentTranslator:
    def __init__(self):
        """åˆå§‹åŒ–ç¿»è¯‘å™¨"""
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        self.api_key = os.getenv('YUNWU_API_KEY')
        self.base_url = os.getenv('YUNWU_BASE_URL', 'https://yunwu.ai/v1')
        self.model = os.getenv('YUNWU_MODEL', 'gpt-3.5-turbo')
        
        # éªŒè¯APIé…ç½®
        if not self.api_key or self.api_key == 'your-api-key-here':
            raise ValueError("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® YUNWU_API_KEY")
        
        # åˆ›å»ºç¦ç”¨SSLéªŒè¯çš„httpxå®¢æˆ·ç«¯
        self.httpx_client = httpx.AsyncClient(
            verify=False,  # ç¦ç”¨SSLéªŒè¯
            timeout=httpx.Timeout(60.0),
            limits=httpx.Limits(max_keepalive_connections=20, max_connections=100)
        )
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
        self.openai_client = AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
            http_client=self.httpx_client
        )
        
        # è·¯å¾„é…ç½®
        self.docs_path = Path(project_root) / 'docs'
        self.output_path = Path(project_root) / 'docs_cn'
        self.output_path.mkdir(exist_ok=True)
        
        # æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
        self.supported_extensions = {'.md', '.rst'}
        
        # ä¸éœ€è¦ç¿»è¯‘çš„æ–‡ä»¶/ç›®å½•
        self.skip_patterns = {
            '_build', '__pycache__', '.git', 
            'requirements-docs.txt', 'Makefile', 'conf.py'
        }
        
        # å¹¶å‘æ§åˆ¶
        self.semaphore = asyncio.Semaphore(3)  # æœ€å¤š3ä¸ªå¹¶å‘è¯·æ±‚

    def should_skip_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ­¤æ–‡ä»¶"""
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if file_path.suffix not in self.supported_extensions:
            return True
            
        # æ£€æŸ¥è·³è¿‡æ¨¡å¼
        for pattern in self.skip_patterns:
            if pattern in str(file_path):
                return True
                
        return False

    def is_already_translated(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»ç¿»è¯‘"""
        output_file = self.output_path / file_path.relative_to(self.docs_path)
        return output_file.exists()

    def is_content_chinese(self, content: str) -> bool:
        """æ£€æµ‹å†…å®¹æ˜¯å¦å·²ç»æ˜¯å®Œæ•´çš„ä¸­æ–‡"""
        if len(content) < 50:
            return False
        
        # è®¡ç®—ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹
        chinese_chars = sum(1 for char in content if '\u4e00' <= char <= '\u9fff')
        english_chars = sum(1 for char in content if char.isalpha() and not '\u4e00' <= char <= '\u9fff')
        
        # å¦‚æœä¸­æ–‡å­—ç¬¦å¤šäºè‹±æ–‡å­—ç¬¦çš„70%ï¼Œè®¤ä¸ºæ˜¯ä¸­æ–‡
        if english_chars == 0:
            return chinese_chars > 10  # è‡³å°‘æœ‰ä¸€äº›ä¸­æ–‡å­—ç¬¦
        
        return chinese_chars > english_chars * 0.7

    def is_translation_incomplete(self, file_path: Path) -> bool:
        """æ£€æŸ¥ç¿»è¯‘æ˜¯å¦ä¸å®Œæ•´"""
        output_file = self.output_path / file_path.relative_to(self.docs_path)
        if not output_file.exists():
            return True
            
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¤§é‡è‹±æ–‡å†…å®¹
            lines = content.split('\n')
            english_lines = 0
            total_text_lines = 0
            
            for line in lines:
                line = line.strip()
                # è·³è¿‡ä»£ç å—ã€é“¾æ¥ç­‰
                if (not line or line.startswith('```') or line.startswith('http') or 
                    line.startswith('![') or line.startswith('.. ') or 
                    line.startswith('#') and len(line.split()) == 1):
                    continue
                    
                total_text_lines += 1
                # æ£€æŸ¥æ˜¯å¦ä¸»è¦æ˜¯è‹±æ–‡
                english_chars = sum(1 for char in line if char.isalpha() and not '\u4e00' <= char <= '\u9fff')
                chinese_chars = sum(1 for char in line if '\u4e00' <= char <= '\u9fff')
                
                if english_chars > chinese_chars and english_chars > 10:
                    english_lines += 1
            
            # å¦‚æœè¶…è¿‡30%çš„æ–‡æœ¬è¡Œä»æ˜¯è‹±æ–‡ï¼Œè®¤ä¸ºç¿»è¯‘ä¸å®Œæ•´
            if total_text_lines > 0:
                english_ratio = english_lines / total_text_lines
                return english_ratio > 0.3
                
            return False
            
        except Exception as e:
            print(f"    âš ï¸  æ£€æŸ¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return True

    async def translate_text(self, text: str, context: str = "", max_retries: int = 3) -> str:
        """ä½¿ç”¨å¼‚æ­¥APIç¿»è¯‘æ–‡æœ¬"""
        if not text.strip():
            return text
            
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£ç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹è‹±æ–‡æŠ€æœ¯æ–‡æ¡£ç¿»è¯‘æˆä¸­æ–‡ï¼Œè¦æ±‚ï¼š

1. ä¿æŒæŠ€æœ¯æœ¯è¯­çš„å‡†ç¡®æ€§
2. ä¿ç•™åŸæœ‰çš„æ ¼å¼æ ‡è®°ï¼ˆå¦‚Markdownã€reStructuredTextæ ¼å¼ï¼‰
3. ä¿æŒä»£ç å—ã€é“¾æ¥ã€å›¾ç‰‡ç­‰ä¸å˜
4. ç¿»è¯‘è¦è‡ªç„¶æµç•…ï¼Œç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯
5. ä¸“ä¸šæœ¯è¯­å¯ä»¥åœ¨é¦–æ¬¡å‡ºç°æ—¶ä½¿ç”¨"ä¸­æ–‡(è‹±æ–‡)"çš„å½¢å¼
6. ä¿ç•™æ‰€æœ‰çš„æ ‡é¢˜å±‚çº§å’Œç»“æ„
7. ç¡®ä¿å®Œæ•´ç¿»è¯‘ï¼Œä¸è¦é—æ¼ä»»ä½•æ–‡æœ¬å†…å®¹

è¯·ç›´æ¥è¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦æ·»åŠ é¢å¤–è¯´æ˜ã€‚"""

        user_prompt = f"""æ–‡æ¡£ä¸Šä¸‹æ–‡: {context}

éœ€è¦ç¿»è¯‘çš„å†…å®¹:
{text}"""

        for attempt in range(max_retries):
            try:
                async with self.semaphore:
                    print(f"    APIè°ƒç”¨ä¸­... (å°è¯• {attempt + 1}/{max_retries})")
                    
                    response = await self.openai_client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.2,
                        max_tokens=4000
                    )
                    
                    translated = response.choices[0].message.content.strip()
                    print(f"    âœ“ ç¿»è¯‘æˆåŠŸ")
                    return translated
                    
            except Exception as e:
                print(f"    âœ— ç¿»è¯‘è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    
        print(f"    âŒ ç¿»è¯‘å¤±è´¥ï¼Œè¿”å›åŸæ–‡")
        return text

    def split_content(self, content: str) -> List[str]:
        """å°†å†…å®¹åˆ†å‰²æˆé€‚åˆç¿»è¯‘çš„æ®µè½"""
        # æŒ‰åŒæ¢è¡Œç¬¦åˆ†å‰²æ®µè½
        paragraphs = content.split('\n\n')
        
        chunks = []
        current_chunk = ""
        
        for paragraph in paragraphs:
            # å¦‚æœæ˜¯ä»£ç å—ã€é“¾æ¥ç­‰ç‰¹æ®Šå†…å®¹ï¼Œå•ç‹¬å¤„ç†
            if (paragraph.startswith('```') or 
                paragraph.startswith('.. code-block::') or
                paragraph.startswith('http') or
                paragraph.startswith('![') or
                paragraph.startswith('.. image::') or
                len(paragraph.split()) < 3):
                
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = ""
                chunks.append(paragraph)
            else:
                if len(current_chunk) + len(paragraph) > 1200:  # æ§åˆ¶æ¯å—å¤§å°
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    current_chunk = paragraph
                else:
                    current_chunk += "\n\n" + paragraph if current_chunk else paragraph
        
        if current_chunk:
            chunks.append(current_chunk.strip())
            
        return [chunk for chunk in chunks if chunk.strip()]

    async def translate_file(self, file_path: Path, force: bool = False) -> bool:
        """å¼‚æ­¥ç¿»è¯‘å•ä¸ªæ–‡ä»¶"""
        try:
            print(f"æ­£åœ¨å¤„ç†: {file_path}")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»ç¿»è¯‘ï¼ˆé™¤éå¼ºåˆ¶ç¿»è¯‘ï¼‰
            output_file = self.output_path / file_path.relative_to(self.docs_path)
            
            # æ£€æŸ¥ç¿»è¯‘æ˜¯å¦ä¸å®Œæ•´
            is_incomplete = self.is_translation_incomplete(file_path)
            
            if not force and output_file.exists() and not is_incomplete:
                print(f"  â­ï¸  æ–‡ä»¶å·²å®Œæ•´ç¿»è¯‘ï¼Œè·³è¿‡: {output_file}")
                return True
            elif is_incomplete:
                print(f"  ğŸ”„ æ£€æµ‹åˆ°ç¿»è¯‘ä¸å®Œæ•´ï¼Œé‡æ–°ç¿»è¯‘")
            
            # è¯»å–åŸæ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            print(f"  ğŸ“„ æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯å®Œæ•´çš„ä¸­æ–‡å†…å®¹
            if not force and self.is_content_chinese(content):
                print(f"  ğŸ‡¨ğŸ‡³ å†…å®¹å·²ç»æ˜¯å®Œæ•´ä¸­æ–‡ï¼Œç›´æ¥å¤åˆ¶")
                output_file.parent.mkdir(parents=True, exist_ok=True)
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                return True
            
            # æ£€æŸ¥æ˜¯å¦ä¸»è¦æ˜¯ä»£ç æ–‡ä»¶
            code_block_count = content.count('```')
            total_lines = content.count('\n') + 1
            if code_block_count > 0 and code_block_count > total_lines / 3:
                print(f"  ğŸ’» ä¸»è¦æ˜¯ä»£ç å†…å®¹ï¼Œç›´æ¥å¤åˆ¶")
                output_file.parent.mkdir(parents=True, exist_ok=True)
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                return True
            
            # åˆ†å‰²å†…å®¹è¿›è¡Œç¿»è¯‘
            chunks = self.split_content(content)
            print(f"  ğŸ“ å¼€å§‹ç¿»è¯‘ï¼Œå…± {len(chunks)} ä¸ªç‰‡æ®µ")
            
            # å¼‚æ­¥ç¿»è¯‘æ‰€æœ‰ç‰‡æ®µ
            translated_chunks = []
            
            for i, chunk in enumerate(chunks):
                print(f"    [{i+1}/{len(chunks)}] æ­£åœ¨ç¿»è¯‘ç‰‡æ®µ...")
                
                # å¦‚æœæ˜¯ä»£ç å—æˆ–ç‰¹æ®Šæ ¼å¼ï¼Œä¸ç¿»è¯‘
                if (chunk.startswith('```') or 
                    chunk.startswith('.. code-block::') or
                    chunk.startswith('http') or
                    chunk.startswith('![') or
                    chunk.startswith('.. image::') or
                    len(chunk.split()) < 2):  # å¾ˆçŸ­çš„å†…å®¹
                    print(f"    â­ï¸  ç‰¹æ®Šæ ¼å¼ï¼Œè·³è¿‡ç¿»è¯‘")
                    translated_chunks.append(chunk)
                else:
                    context = f"æ–‡ä»¶: {file_path.name}"
                    translated = await self.translate_text(chunk, context)
                    translated_chunks.append(translated)
                
                # çŸ­æš‚å»¶æ—¶
                await asyncio.sleep(0.3)
            
            # åˆå¹¶ç¿»è¯‘ç»“æœ
            translated_content = '\n\n'.join(translated_chunks)
            
            # ä¿å­˜ç¿»è¯‘æ–‡ä»¶
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(translated_content)
                
            print(f"  âœ… ç¿»è¯‘å®Œæˆ: {output_file}")
            return True
            
        except Exception as e:
            print(f"  âŒ ç¿»è¯‘å¤±è´¥ {file_path}: {e}")
            return False

    def get_all_files(self) -> List[Path]:
        """è·å–æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„æ–‡ä»¶"""
        all_files = []
        
        for ext in self.supported_extensions:
            pattern = f"**/*{ext}"
            files = list(self.docs_path.glob(pattern))
            all_files.extend(files)
        
        # è¿‡æ»¤æ‰ä¸éœ€è¦ç¿»è¯‘çš„æ–‡ä»¶
        filtered_files = [f for f in all_files if not self.should_skip_file(f)]
        
        return sorted(filtered_files)

    def create_chinese_conf(self):
        """åˆ›å»ºä¸­æ–‡æ–‡æ¡£çš„é…ç½®æ–‡ä»¶"""
        conf_content = '''# -*- coding: utf-8 -*-
"""
ä¸­æ–‡æ–‡æ¡£é…ç½®æ–‡ä»¶
åŸºäºåŸæ–‡æ¡£é…ç½®ä¿®æ”¹
"""

# å¯¼å…¥åŸé…ç½®
import sys
import os
sys.path.insert(0, os.path.abspath('../docs'))
from conf import *

# ä¿®æ”¹é¡¹ç›®ä¿¡æ¯ä¸ºä¸­æ–‡
project = "verl - ä¸­æ–‡æ–‡æ¡£"
copyright = "2024 ByteDance Seed Foundation MLSys Team"
author = "Guangming Sheng, Chi Zhang, Yanghua Peng, Haibin Lin"

# è¯­è¨€è®¾ç½®
language = "zh_CN"

# HTMLé…ç½®
html_title = "VERL ä¸­æ–‡æ–‡æ¡£"
html_short_title = "VERL ä¸­æ–‡æ–‡æ¡£"

# GitHub Pages ä¸­æ–‡æ–‡æ¡£é…ç½®
html_baseurl = "https://vocabvictor.github.io/verl-ascend/zh/"

# ä¸»é¢˜é€‰é¡¹
html_theme_options.update({
    'navigation_depth': 4,
    'collapse_navigation': False,
    'sticky_navigation': True,
    'includehidden': True,
    'titles_only': False
})
'''
        
        conf_file = self.output_path / 'conf.py'
        with open(conf_file, 'w', encoding='utf-8') as f:
            f.write(conf_content)
        
        print(f"âœ… åˆ›å»ºä¸­æ–‡é…ç½®æ–‡ä»¶: {conf_file}")

    def create_makefile(self):
        """åˆ›å»ºä¸­æ–‡æ–‡æ¡£çš„Makefile"""
        makefile_content = '''# ä¸­æ–‡æ–‡æ¡£ Makefile

SPHINXOPTS    =
SPHINXBUILD   = sphinx-build
SPHINXPROJ    = verl-cn
SOURCEDIR     = .
BUILDDIR      = _build

.PHONY: help Makefile

help:
\t@$(SPHINXBUILD) -M help "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)

%: Makefile
\t@$(SPHINXBUILD) -M $@ "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)
'''
        
        makefile = self.output_path / 'Makefile'
        with open(makefile, 'w', encoding='utf-8') as f:
            f.write(makefile_content)
        
        print(f"âœ… åˆ›å»ºä¸­æ–‡Makefile: {makefile}")

    async def run_translation(self, force: bool = False, check_incomplete: bool = True):
        """æ‰§è¡Œå®Œæ•´çš„ç¿»è¯‘æµç¨‹"""
        print("ğŸš€ å¼€å§‹å¼‚æ­¥æ–‡æ¡£ç¿»è¯‘...")
        print(f"æºç›®å½•: {self.docs_path}")
        print(f"è¾“å‡ºç›®å½•: {self.output_path}")
        print(f"APIåœ°å€: {self.base_url}")
        print(f"å¼ºåˆ¶é‡æ–°ç¿»è¯‘: {'æ˜¯' if force else 'å¦'}")
        print(f"æ£€æŸ¥ä¸å®Œæ•´ç¿»è¯‘: {'æ˜¯' if check_incomplete else 'å¦'}")
        print("-" * 50)
        
        # è·å–æ‰€æœ‰æ–‡ä»¶
        files = self.get_all_files()
        print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")
        
        if not files:
            print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦ç¿»è¯‘çš„æ–‡ä»¶")
            return
        
        # å¦‚æœéœ€è¦æ£€æŸ¥ä¸å®Œæ•´ç¿»è¯‘ï¼Œå…ˆæ‰«æä¸€é
        if check_incomplete and not force:
            print("\nğŸ“‹ æ£€æŸ¥ç¿»è¯‘å®Œæ•´æ€§...")
            incomplete_files = []
            for file_path in files:
                if self.is_translation_incomplete(file_path):
                    incomplete_files.append(file_path)
            
            if incomplete_files:
                print(f"å‘ç° {len(incomplete_files)} ä¸ªä¸å®Œæ•´ç¿»è¯‘æ–‡ä»¶ï¼Œå°†é‡æ–°ç¿»è¯‘")
                for f in incomplete_files[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                    print(f"  - {f}")
                if len(incomplete_files) > 5:
                    print(f"  ... è¿˜æœ‰ {len(incomplete_files) - 5} ä¸ªæ–‡ä»¶")
        
        # ç¿»è¯‘æ–‡ä»¶
        success_count = 0
        skip_count = 0
        
        for i, file_path in enumerate(files, 1):
            print(f"\n[{i}/{len(files)}] ", end="")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡
            if not force and not check_incomplete and self.is_already_translated(file_path):
                print(f"â­ï¸  è·³è¿‡å·²ç¿»è¯‘: {file_path}")
                skip_count += 1
                continue
                
            if await self.translate_file(file_path, force):
                success_count += 1
        
        # åˆ›å»ºé…ç½®æ–‡ä»¶
        print(f"\nğŸ“ åˆ›å»ºä¸­æ–‡æ–‡æ¡£é…ç½®...")
        self.create_chinese_conf()
        self.create_makefile()
        
        # å¤åˆ¶é™æ€æ–‡ä»¶
        import shutil
        static_src = self.docs_path / '_static'
        if static_src.exists():
            static_dst = self.output_path / '_static'
            if static_dst.exists():
                shutil.rmtree(static_dst)
            shutil.copytree(static_src, static_dst)
            print(f"âœ… å¤åˆ¶é™æ€æ–‡ä»¶: {static_dst}")
        
        print(f"\nğŸ‰ å¼‚æ­¥ç¿»è¯‘å®Œæˆ!")
        print(f"æˆåŠŸç¿»è¯‘: {success_count} ä¸ªæ–‡ä»¶")
        print(f"è·³è¿‡å·²æœ‰: {skip_count} ä¸ªæ–‡ä»¶")
        print(f"æ€»è®¡å¤„ç†: {success_count + skip_count}/{len(files)} ä¸ªæ–‡ä»¶")
        print(f"è¾“å‡ºç›®å½•: {self.output_path}")
        print(f"\næ„å»ºä¸­æ–‡æ–‡æ¡£:")
        print(f"cd {self.output_path}")
        print(f"make html")

    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯è¿æ¥"""
        await self.httpx_client.aclose()
        await self.openai_client.close()


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¼‚æ­¥ç¿»è¯‘æ–‡æ¡£å·¥å…·')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°ç¿»è¯‘æ‰€æœ‰æ–‡ä»¶')
    parser.add_argument('--no-check', action='store_true', help='ä¸æ£€æŸ¥ä¸å®Œæ•´ç¿»è¯‘')
    args = parser.parse_args()
    
    translator = None
    try:
        translator = AsyncDocumentTranslator()
        await translator.run_translation(
            force=args.force, 
            check_incomplete=not args.no_check
        )
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("\nè¯·æ£€æŸ¥:")
        print("1. .env æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”é…ç½®æ­£ç¡®")
        print("2. APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ")
        print("3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        sys.exit(1)
    finally:
        if translator:
            await translator.close()


if __name__ == "__main__":
    asyncio.run(main())